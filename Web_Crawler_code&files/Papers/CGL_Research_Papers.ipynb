{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f27103c",
   "metadata": {
    "id": "0f27103c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL:https://pureportal.coventry.ac.uk/en/persons/sian-alsop/publications\n",
      "19\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/dimitar-angelov/publications\n",
      "7\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/rami-ayoubi/publications\n",
      "76\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/ema-baukaite/publications\n",
      "0\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/julia-carroll/publications\n",
      "51\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/jacqueline-cawston-2/publications\n",
      "14\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/megan-crawford/publications\n",
      "50\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/que-anh-dang/publications\n",
      "16\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/alun-dewinter/publications\n",
      "12\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/ken-fero/publications\n",
      "21\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/mark-hodds/publications\n",
      "18\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/sylwia-holmes/publications\n",
      "11\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/elizabeth-horton/publications\n",
      "33\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/jaya-jacobo/publications\n",
      "6\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/emmanuel-johnson/publications\n",
      "13\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/mehmet-karakus/publications\n",
      "52\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/luca-morini/publications\n",
      "53\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/marina-orsini-jones/publications\n",
      "46\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/charlotte-price/publications\n",
      "21\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/steve-raven/publications\n",
      "3\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/carlo-tramontano/publications\n",
      "42\n",
      "URL:https://pureportal.coventry.ac.uk/en/persons/katherine-wimpenny/publications\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "import json\n",
    "browser = webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "\n",
    "browser.get(\"https://pureportal.coventry.ac.uk/en/organisations/centre-global-learning/persons/\")    # Coventry URL Site\n",
    "time.sleep(5)\n",
    "browser.find_element(By.XPATH,\"//button[@id='onetrust-accept-btn-handler']\").click() # Accept Cookies\n",
    "\n",
    "for i in range(0 , 1):\n",
    "    \n",
    "        # Profiles per Page\n",
    "        Cov_Page_Url = \"https://pureportal.coventry.ac.uk/en/organisations/centre-global-learning/persons/?page=%d\"%(i)\n",
    "        browser.get(Cov_Page_Url)\n",
    "        a = browser.page_source\n",
    "        resp=BeautifulSoup(a,\"html.parser\")\n",
    "        \n",
    "        Cov_Page_Profiles = resp.find(class_ = 'grid-results')\n",
    "        Cov_Page_Profiles_2 = Cov_Page_Profiles.find_all('h3') # User details\n",
    "        \n",
    "        # Load Each Profile in page\n",
    "        for prof in Cov_Page_Profiles_2:\n",
    "            \n",
    "            Profile_Url = prof.find('a')\n",
    "            Profile_Url_2 = Profile_Url['href'] + '/publications'\n",
    "            time.sleep(5)\n",
    "            print(\"URL:\" + Profile_Url_2)\n",
    "            browser.get(Profile_Url_2)\n",
    "            b = browser.page_source\n",
    "            resp1 = BeautifulSoup(b,\"html.parser\")\n",
    "            \n",
    "#             Research_Output = browser.find_element_by_xpath(\"/html/body/main/div[1]/section/div[2]/div/div/nav/ul/li[4]/a/span/i\")\n",
    "\n",
    "            if(resp1.find(class_='icon icon-publications') != None):\n",
    "                Cov_Research_Paper = resp1.find(class_='list-results')\n",
    "                Cov_Research_Paper_2 = Cov_Research_Paper.find_all('h3')   #Research Papers Count in the first page\n",
    "                \n",
    "                # Create Empty array to store URL's of User Research Paper\n",
    "                urls=[]\n",
    "                \n",
    "                for paper in Cov_Research_Paper_2:\n",
    "                    Cov_Research_Paper_3 = paper.find('a')\n",
    "                    Cov_Research_Paper_4 = Cov_Research_Paper_3['href'] # each research paper\n",
    "                    urls.append(Cov_Research_Paper_4)\n",
    "                    \n",
    "                try:\n",
    "                    while(browser.find_element(By.XPATH,\"/html/body/main/div[1]/div/div/section/nav/ul/li[3]/a\") != None):\n",
    "                        Res_Pap_Page = resp1.find(class_='next')\n",
    "    #                     Resp_Pap_Page_2 = Res_Pap_Page.find(class_='next')\n",
    "                        Res_Pap_Page_3 = Res_Pap_Page.find('a')\n",
    "                        Research_Url = 'https://pureportal.coventry.ac.uk' + Res_Pap_Page_3['href']\n",
    "                        browser.get(Research_Url)\n",
    "                        time.sleep(5)\n",
    "#                         browser.find_element(By.XPATH,\"/html/body/main/div[1]/div/div/section/nav/ul/li[3]/a\").click()\n",
    "                        e = browser.page_source\n",
    "                        resp2 = BeautifulSoup(e,\"html.parser\")\n",
    "                        Cov_Research_Paper = resp2.find(class_='list-results')\n",
    "                        Cov_Research_Paper_2 = Cov_Research_Paper.find_all('h3') #Research Papers Count in the consecutive page\n",
    "                        for paper in Cov_Research_Paper_2:\n",
    "                            Cov_Research_Paper_3 = paper.find('a')\n",
    "                            Cov_Research_Paper_4 = Cov_Research_Paper_3['href'] # each research paper\n",
    "                            urls.append(Cov_Research_Paper_4)\n",
    "                except:\n",
    "                    time.sleep(0)\n",
    "                \n",
    "#                 print(urls)\n",
    "                    \n",
    "                print(len(urls))\n",
    "                for Cov_Pap in urls:\n",
    "\n",
    "                    browser.get(Cov_Pap)\n",
    "                    time.sleep(2)\n",
    "                    c = browser.page_source\n",
    "                    resp3=BeautifulSoup(c,\"html.parser\")\n",
    "            \n",
    "                    Res_Title = resp3.find(class_='rendering')\n",
    "                    Cov_Title = Res_Title.get_text()\n",
    "                        \n",
    "                    Res_Dept = resp3.find(class_='relations organisations')    # Capture Department Details                        \n",
    "                    if(Res_Dept != None):\n",
    "                        Cov_Dept_2 = Res_Dept.find('a')\n",
    "                        if(Cov_Dept_2 != None):\n",
    "                            Cov_Department = Cov_Dept_2.get_text()\n",
    "                        else:\n",
    "                            Cov_Department = \"\"\n",
    "                    else:\n",
    "                        Cov_Department = \"\"\n",
    "                            \n",
    "                    Res_Year = resp3.find(class_='status')     # Publication Year\n",
    "                    if(Res_Year != None):\n",
    "                        Cov_Publ = Res_Year.find(class_='date')\n",
    "                        Cov_Publ_2 = Cov_Publ.get_text()\n",
    "                        Cov_Year = Cov_Publ_2[-4:]\n",
    "                    else:\n",
    "                        Cov_Year = \"\"\n",
    "                            \n",
    "                    Res_Doc = resp3.find(class_='content-sidebar publication-sidebar')    # Access to Doc Link\n",
    "                    Cov_Doc_2 = resp3.find(class_='doi')\n",
    "                    if(Res_Doc != None and Cov_Doc_2 != None):\n",
    "                        Cov_Doc_3 = Cov_Doc_2.find('a')\n",
    "                        Cov_Document = Cov_Doc_3['href']\n",
    "                    else:\n",
    "                        Cov_Document = \"\"\n",
    "                            \n",
    "                    Res_Abstract = resp3.find(class_='textblock')             # Research_Paper_Abstract\n",
    "                    if(Res_Abstract != None):\n",
    "                        Cov_Abstract = Res_Abstract.get_text()\n",
    "                    else:\n",
    "                        Cov_Abstract = \"\"\n",
    "\n",
    "                    authors = resp3.find(class_='relations persons')\n",
    "                    if(authors != None):\n",
    "                        Cov_Authors = authors.get_text()\n",
    "                    else:\n",
    "                        Cov_Authors = \"\"\n",
    "\n",
    "                    if(resp3.find(class_= 'icon icon-fingerprint') != None):\n",
    "                        interests = []\n",
    "                        FP_Url = Cov_Pap + '/fingerprints'\n",
    "                        browser.get(FP_Url)\n",
    "                        d = browser.page_source\n",
    "                        time.sleep(2)\n",
    "                        resp4 = BeautifulSoup(d,\"html.parser\")\n",
    "                        Res_FP = resp4.find_all(class_='publication-fingerprint-thesauri')\n",
    "                        if (Res_FP != None):\n",
    "                            for fp in Res_FP:\n",
    "                                Cov_Interests = fp.find('h3').get_text()\n",
    "                                interests.append(Cov_Interests)\n",
    "                            Cov_Interests = ','.join(interests)\n",
    "                        else:\n",
    "                            Cov_Interests = \"\"\n",
    "                    else:\n",
    "                        Cov_Interests = \"\"\n",
    "                        \n",
    "                    Scrapped_Cov_Data = {\n",
    "                            'Title': Cov_Title,\n",
    "                            'Publications Authors': Cov_Authors,\n",
    "                            'Department': Cov_Department,\n",
    "                            'Publication Year': Cov_Year,\n",
    "                            'Paper Link': Cov_Pap,\n",
    "                            'Tags':Cov_Interests,\n",
    "                            'Access to Doc.': Cov_Document,\n",
    "                            'Abstract':Cov_Abstract\n",
    "                          }\n",
    "\n",
    "                    with open(\"Final_Cov_Research_Paper.json\", \"a+\") as outfile:\n",
    "                        json.dump(Scrapped_Cov_Data, outfile)\n",
    "                        outfile.write(\"\\n\")\n",
    "            else:\n",
    "                time.sleep(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce03a0d",
   "metadata": {
    "id": "cce03a0d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
